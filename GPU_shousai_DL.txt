【準備＿必須】
    ANACONDA Navigator起動
    minist_buを「GPU_env」としてクローン
    
    pycharm起動
    GPU_shousai_DLプロジェクトワークスペースとして作業する
    このプロジェクトインタープリターを設定する。
        Setting→ProjectInterpritorから、
        Add Local→Existing Enviromment
        先のクローンしたvenv内のpython.exeを指定する。

    CMD
    conda info -e
    activate GPU_env
    (GPU_env)python ***.py
        
【準備＿任意】
    詳細DeepLeatnigのソースコードをGithubからClone(Zip)して、
    (https://github.com/yusugomori/deeplearning-tensorflow-keras)
    GPU_detailDL/deeplearning-tensorflow-keras-masterに配置・参考にする。
    （システム的に連携させたかったが今後の課題）


【気づき】
１）tfのメソッドの活用
    from keras import backend as K
    tf.truncated_normal
    => K.truncated_normal で利用可能となる

    高速化設定
        K.set_floatx('float16')     # default is float32
        K.set_epsilon(1e-4)         # default is 1e-7

２)  Kerasでの、シーケンシャルコーディングの流れ
    １：データセットの定義
        ・データの取り込み
        ・データの選択・変換・補間
        ・データの分割
    ２：モデル定義
        ・パラメタ宣言
        ・シーケンシャル作成
        ・隠れ層への次元圧縮（Dense）
        ・隠れ層での正規化（BatchNormalization）
        ・隠れ層での活性化（Activation）
        ・出力層への次元圧縮（Dense）
        ・出力層への活性化（Activation）
        ・モデルをコンパイル
    ３：学習（fit：トレインで学習、バリデートで無学習データへの適合確認）
    ４：評価（evaluate：テストで無学習データへの適合確認）
    ５：可視化
    ６：（高速化(キャッシュ)・転移学習）

３）リカレントNN
    ・シーケンス(maxlen)と隠れ層数(n_hidden)は無関係
    ・ズレ(スライド＝1)に対するすべてのシーケンスをデータセット化(メモリの無駄) => 解決策？

    １：Truncated BPTT ("Truncated" BackPropagation Through Time , as SimpleRNN)
        ”切り取られた”過去のデータを含むシーケンスとターゲットの関係を学習
        ・全データセットを時間依存性なし学習するため、学習ズレが増幅または直近傾向を無視する学習となるイメージ

    ２：LSTM ("Long short-term memory")
        過去のデータを含むシーケンスとターゲットの関係を"時間依存性"を加味して学習
        ・メモリセル：長期による勾配誤差の消失を回避するため、勾配誤差を記憶
                  　（勾配爆発には勾配クリッピング(勾配閾値による抑制)を用い、制御）
        ・入力ゲート：前時刻情報の隠れ層状態が現シーケンスとして適当に伝達し、
                    重みの相互相殺(入力重み衝突)による長期依存性の学習阻害を回避
        ・出力ゲート：現シーケンスが次時刻情報の隠れ層状態として適当に伝達し、
                    重みの相互相殺(出力重み衝突)による長期依存性の学習阻害を回避
        ・忘却ゲート：変化が発生した傾向を捉えるために、メモリセルを適度に忘れる
        ・覗き穴結合：ニューロン情報の保持・取得・置換可能とするため、構造を持たせる

    ３：GRU（Gated Recurrent Unit）
        LSTMの計算負荷を低減しつつ、過去のデータを含むシーケンスとターゲットの関係を"時間依存性"を加味して学習
        ・リセットゲート：
        ・更新ゲート：

４）双方向リカレントNN
    ・リーケージの概念がない解析に対し適用する(i.e, 翻訳、Q&A、要約)

    １：bidirectional rnn：
        双方向リカレントNNであり、逆行(RNNの順行と逆)の情報も含め学習する
        文章・写真などの多次元データを特定時刻にリーケージなしに得られるデータに適用できる

    ２：encoder/decoder：
        足し算の式と回答のような関係を解析


＝＝＝ 【課題と思ったこと】＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝
１）Function API化
２）リアルタイム可視化
３）Github連携
４）学習データのキャッシュ
５）重みデータのキャッシュ
６）全体のログ化
７）RNN系への入力がシーケンスのスライド集合なのは改善できないか
＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝

３）Github連携
    「GitHubからダウンロードする方法」
    １，GitHubのダウンロードしたいプロジェクトのトップページを開きます。
    ２，画面右上にある Clone or dowload ボタン[1]をクリックします。
    ３，"clone"クリックし、文字列をクリップボードにコピーします。
    ４，gitを動かすためのコマンドプロンプトを開きます。
    ５，git for windows の場合は、エキスプローラでダウンロードするフォルダーを開き、コンテキストメニューでGit Bash Hereを選択して下さい。
    ６，コマンド・プロンプトで以下のコマンドを入力します。
        git clone [3]の部分の文字列
    ・ git for windowsのコマンド・プロンプトの場合、コンテキストメニューでペーストできます。
    ・ 実行すると、レポジトリ名のフォルダーができ、その中にファイルがダウンロードされています。



